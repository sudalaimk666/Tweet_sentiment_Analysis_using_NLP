{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Twitter Sentiment Analysis","metadata":{}},{"cell_type":"markdown","source":"> This kernel is the solution for the challenge launched by School of AI - Algiers, which consist of building a system that can classify tweets as Sad or Happy.","metadata":{}},{"cell_type":"markdown","source":"1. Solution","metadata":{}},{"cell_type":"markdown","source":"> We will start by reading some tweets so we can understand our data better. We will then try to transform our tweets into something usable by different ML models, where we are going to choose the more efficient. We will finally fine tune our model and then test it to see its efficiency on new data.","metadata":{}},{"cell_type":"markdown","source":"# Update","metadata":{}},{"cell_type":"markdown","source":"After getting some comments on the School of AI - Algiers group, especially from Belkacem, I updated the following:\n\nI used lemmatization instead of steaming\nI also noticed that I was mistaken when I stopped the max_features parameter at 20000 while doing GridSearch, I should have tested a bigger one, because if it stopped at 20000 (which is the max), it may get better using a bigger one. I just added None (no limit).","metadata":{}},{"cell_type":"markdown","source":"# Content\n> Loading the data\n> \n> Visualize the tweets\n> \n> Emoticons\n> \n> Most used words\n> \n> Stop words\n> \n> Stemming\n> \n> Prepare the data\n> \n> Bag of Words\n> \n> Building the pipeline\n> \n> Select a model\n> \n> Fine tune the model\n> \n> Testing the model\n> \n> Test your tweet","metadata":{}},{"cell_type":"markdown","source":"# Load the data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# This is for making some large tweets to be displayed\npd.options.display.max_colwidth = 100\n\n# I got some encoding issue, I didn't knew which one to use !\n# This post suggested an encoding that worked!\n# https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte\ntrain_data = pd.read_csv(\"../input/twitter-dataset/train_twitter.csv\")","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        id  label  \\\n0        1      0   \n1        2      0   \n2        3      0   \n3        4      0   \n4        5      1   \n...    ...    ...   \n7915  7916      0   \n7916  7917      0   \n7917  7918      0   \n7918  7919      0   \n7919  7920      0   \n\n                                                                                                    tweet  \n0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #iger...  \n1     Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias…...  \n2     We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connec...  \n3     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr....  \n4     What amazing service! Apple won't even talk to me about a question I have unless I pay them $19....  \n...                                                                                                   ...  \n7915  Live out loud #lol #liveoutloud #selfie #smile #sony #music #headphones https://instagram.com/p/...  \n7916  We would like to wish you an amazing day! Make every minute count #tls #today #iphone #accessori...  \n7917  Helping my lovely 90 year old neighbor with her iPad this morning has just made me realise that ...  \n7918  Finally got my #smart #pocket #wifi stay connected anytime,anywhere! #ipad and #samsung #s3 #gad...  \n7919  Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… h...  \n\n[7920 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #iger...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias…...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connec...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7915</th>\n      <td>7916</td>\n      <td>0</td>\n      <td>Live out loud #lol #liveoutloud #selfie #smile #sony #music #headphones https://instagram.com/p/...</td>\n    </tr>\n    <tr>\n      <th>7916</th>\n      <td>7917</td>\n      <td>0</td>\n      <td>We would like to wish you an amazing day! Make every minute count #tls #today #iphone #accessori...</td>\n    </tr>\n    <tr>\n      <th>7917</th>\n      <td>7918</td>\n      <td>0</td>\n      <td>Helping my lovely 90 year old neighbor with her iPad this morning has just made me realise that ...</td>\n    </tr>\n    <tr>\n      <th>7918</th>\n      <td>7919</td>\n      <td>0</td>\n      <td>Finally got my #smart #pocket #wifi stay connected anytime,anywhere! #ipad and #samsung #s3 #gad...</td>\n    </tr>\n    <tr>\n      <th>7919</th>\n      <td>7920</td>\n      <td>0</td>\n      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… h...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7920 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Visualize the tweets","metadata":{}},{"cell_type":"markdown","source":"# From the tweets above, we can already make some remarks about the data:\n\n> We can see that there is some garbage like '&amp', '&lt' (which are basically used in HTML) that aren't gonna help us in our classification\n\n> In twitter, people mention their friends with tags like @username, there is a lot of them in our data. I was discussing with a friend about the usefulness of tags in our classification, for him, people tend to mention more friends when they are happy, but I think that people may mention people because they made bad things. When we face this kind of uncertainty, it's better to try the different options and evaluate which will do well, this is what we are gonna do.","metadata":{}},{"cell_type":"code","source":"# We will now take a look at random tweets\n# to gain more insights\n\nrand_indexs = np.random.randint(1,len(train_data),50).tolist()\ntrain_data[\"tweet\"][rand_indexs]","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"2414    Gain Followers RT This MUST FOLLOW ME I FOLLOW BACK Follow everyone who rts Gain #iphone #sougof...\n1409    My new headphone #instacool #me #sony #headphone #phone #sound #music http://instagram.com/p/dDN...\n2677    The #Prophet as a #Husband . #iphone : http://ift.tt/2boR0kb #android : http://ift.tt/2aSURcJ #k...\n6376    Hey Guys! Look Motorola-MOTO-G5-Plus-01108NARTL-64GB http://zpr.io/nv8Rv #money #today #life #tw...\n4405    I beat a personal record today on the bike! #vsco #vscocam #greatoutdoors #beautiful #statenisla...\n3170     Welcome ! #birthday #gift #likeit it #surprise you #samsung #s4 http://instagram.com/p/fribPpILv9/\n529     I must go out some job done & 2 spread happiness, in order to reveal #FF #quote #twinagoya #Japa...\n158                                   My phone just deleted every single one of my contacts. #random #apple\n5077    Got my new baby!!!! #samsung #samsungs6 #s6 #galaxy #new #android https://instagram.com/p/9op9KQ...\n5023                       Pretty great actually, takin it one $&@*# at a time #autocorrectfail #day iphone\n7749    My second DIY phone case Just a tad proud ;) #iphone #iphonecase #case #diy #blue #purple #me ht...\n7309    Who’s your #WCW ? Thank you mfortphoto for making me look like a shiny plant go follow and DM fo...\n2231                     My calendar on my iPhone has wiped! Arrrrgggghhhhhhh plus I've lost some contacts!\n2867    Spank, skate.. #skate #lide #day #weed #spank #iphoto #instagood #iph #instamood #iphone… https:...\n5461                         why the $&@*# is my ipod skipping? that's supposed to happen to cds. not mp3s.\n4304    Here you are my dear! #iphone #iphone6plus #apple ly #amazing me… http://instagram.com/p/uIHG17x...\n1832    Happiness. :) #mirror #sony #xperia #XperiaP #transparent http://instagr.am/p/TNYFShGKCF/ : Happ...\n4696    #Samsung #GalaxyS5 keyboard bug together with #Google ADM \"lock\" button will brick your phone. T...\n3095    We would like to wish you an amazing day! Make every minute count #tls #today #iphone #accessori...\n7614    A picture is a poem without words. - Horace #sunset #iphone #colorful #hand #summer #beautiful …...\n1228                                           Just got the #ipad! Whop whop lol officially #Apple user lol\n7144    Rainbow~~ #PHOTOOFTHEDAY #photo #rainbow #singapore #camera #sky #samsung #bestofheday #beautifu...\n1939    One more #selfie #summer #feeling #clothes #fashion #vlog #vibes #apple #mirror #hipster… https:...\n1271    still no security updates for #apple #safari regarding unsafe SSL certificates. even microsoft d...\n2339    Photo: #tattoos #friends #iPhone #glasses #fierce #whitetees rs #favorites (Taken with instagram...\n4909    Do you bold #colours then @PureMe_Design is a must have #case for your #iPhone @Harvey_Nichols @...\n275     Alternative Power Fix for #Apple Cinema Display 23\", priceless! Just take a random 24Volt Power ...\n1977    Work just blessed me with a new iphone 5c, #iphone #new #work #phone http://instagram.com/p/fn9_...\n3972    These emergency alerts are really getting old. Second time it scared the crap out of me iphone #...\n3889    Love TWD #iphonesia, #iphone, #instagood, #instagram, #photooftheday, #tweegram, , #iphoneonly,…...\n3423    Fckin hate when all my apple cables break ughh tha agony #apple #iphone #hurts #cablebroke #4sprobs\n4874    Photo: Good morning have a nice day #mirror #selfie #morning ly #smile #samsung #boy #xoxo... ht...\n5672    Flying in the #alps is so much fun! Cool mission today, stay tuned for some awesome stuff #flyin...\n3198    @AppleSupport #hateapple because you could not make my refund, visited covent garden store, they...\n1899    How to Say \"I You More Than My #iPhone\" [Image Cache] http://goo.gl/fb/3Agb Gizmodo.com #imagecache\n6185                                        Winning A Phone @ Work On Fri 13th #Opposites #Sony #Xperia #SP\n5301    Artist Goin #iphonesia #photooftheday #iphone #iphoneonly #jj #instagood #iphone4 #ig #sky #iger...\n3960    What's happiness to you? Get your phone that extra layer of protection and celebrate happiness w...\n4128    @davidllo my iMessage (receive) seems to pick on choose upon which device I get my message .. apple\n3656                                          I love the new iOS 9.3 update! #iOS #update it #apple #iphone\n3494    Follow @capetownsup on Instagram http://mf.tt/oYthR #sup #surf #fun #capetown #funny #sexy #me #...\n3447    ⓒ This is the part when I break free. #minions #cute #redhair #piercing #samsung #smile pic.twit...\n1430    Winter is here and so is my mums apple pie #tasty #apple pie#pastry#sugar #sweets #homemade http...\n2737    Free your mind . . . . . #hilltop #sony thyself #lifeisbeautiful #instagood … https://www.instag...\n685     I You #iPhone Protective #Skins - Choose your #Apple iPhone model and buy a Unique piece of Art ...\n3901    Simple makeup dayyyy #instapic #samsung #s4 #makeup #revlon #ysl #itcosmetics… http://instagram....\n4761           100odd MB Available> want to make space> deletes tons of photos> 84.1MB Available... #APPLE.\n4270         my very own samsung edge 6. #contented #blessed #samsung # https://instagram.com/p/4p0eF1sFPe/\n961     Bought a PS3 a year ago for The Last Guardian, now it's getting cancelled? I am one pissed off p...\n2760    FINALLY! Trello on Android!!! So happy!! X) #trello #app #android #samsung #galaxy #awesome #fin...\nName: tweet, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Note\n> you will not have the same results at each execution because of the randomization. For me, after some execution, I noticed this:\n\n> There is tweets with a url (like tweet 35546): we must think about a way to handle URLs, I thought about deleting them because a domain name or the protocol used will not make someone happy or sad unless the domain name is 'food.com'.\n\n> The use of hashtags: we should keep only the words without '#' so words like python and the hashtag '#python' can be seen as the same word, and of course they are.\n> Words like 'as', 'to' and 'so' should be deleted, because they only serve as a way to link phrases and words","metadata":{}},{"cell_type":"markdown","source":"# Emoticons\n> The internet language includes so many emoticons, people also tend to create their own, so we will first analyze the emoticons included in our dataset, try to classify them as happy and said, and make sure that our model know about them.","metadata":{}},{"cell_type":"code","source":"# We are gonna find what emoticons are used in our dataset\nimport re\ntweets_text = train_data.tweet.str.cat()\nemos = set(re.findall(r\" ([xX:;][-']?.) \",tweets_text))\nemos_count = []\nfor emo in emos:\n    emos_count.append((tweets_text.count(emo), emo))\nsorted(emos_count,reverse=True)","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[(4493, ':/'),\n (200, ':)'),\n (77, ':D'),\n (43, 'x.'),\n (35, 'xx'),\n (33, ':3'),\n (32, ':('),\n (31, ';)'),\n (26, 'xD'),\n (22, 'XZ'),\n (20, ':-)'),\n (17, 'XD'),\n (14, ';-)'),\n (9, 'X.'),\n (9, ':P'),\n (8, ':*'),\n (6, ':-D'),\n (5, ':O'),\n (4, ':-('),\n (4, \":')\"),\n (3, ';p'),\n (3, ':|'),\n (3, ':p'),\n (3, ':]'),\n (3, '::'),\n (2, ';D'),\n (2, ':o'),\n (2, ':@'),\n (1, 'x)'),\n (1, 'X)'),\n (1, ';I'),\n (1, ':v'),\n (1, ':-p'),\n (1, ':-/'),\n (1, ':-*'),\n (1, \":'(\")]"},"metadata":{}}]},{"cell_type":"markdown","source":"> We should by now know which emoticons are used (and its frequency) to build two regex, one for the happy ones and another for the sad ones. We will then use them in the preprocessing process to mark them as using happy emoticons or sad ones.","metadata":{}},{"cell_type":"code","source":"HAPPY_EMO = r\" ([xX;:]-?[dD)]|:-?[\\)]|[;:][pP]) \"\nSAD_EMO = r\" (:'?[/|\\(]) \"\nprint(\"Happy emoticons:\", set(re.findall(HAPPY_EMO, tweets_text)))\nprint(\"Sad emoticons:\", set(re.findall(SAD_EMO, tweets_text)))","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Happy emoticons: {':-D', ';)', 'XD', ':P', 'x)', ':p', ':)', 'xD', ';D', 'X)', ';p', ':-)', ':D', ';-)'}\nSad emoticons: {\":'(\", ':/', ':|', ':('}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Most used words\n> What we are going to do next is to define a function that will show us top words, so we may fix things before running our learning algorithm. This function takes as input a text and output words sorted according to their frequency, starting with the most used word.","metadata":{}},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9533fb74b295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"],"ename":"NameError","evalue":"name 'nltk' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\n\n# Uncomment this line if you haven't downloaded punkt before\n# or just run it as it is and uncomment it if you got an error.\n#nltk.download('punkt')\ndef most_used_words(text):\n    tokens = word_tokenize(text)\n    frequency_dist = nltk.FreqDist(tokens)\n    print(\"There is %d different words\" % len(set(tokens)))\n    return sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"most_used_words(train_data.tweet.str.cat())[:100]","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"There is 28800 different words\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['#',\n ':',\n '!',\n 'http',\n '.',\n 'iphone',\n '@',\n ',',\n 'my',\n 'to',\n 'the',\n 'I',\n 'apple',\n 'a',\n 'and',\n 'iPhone',\n '&',\n '...',\n 'for',\n 'https',\n 'it',\n '?',\n 'samsung',\n 'Apple',\n 'is',\n 'phone',\n 'you',\n 'new',\n 'me',\n 'of',\n 'on',\n 'in',\n '$',\n 'with',\n \"n't\",\n '…',\n \"'s\",\n 'sony',\n '*',\n ')',\n 'Samsung',\n 'this',\n 'have',\n 'life',\n 'like',\n 'at',\n '-',\n 'an',\n 'that',\n 'your',\n 'so',\n 'FOLLOW',\n 'now',\n 'cute',\n 'day',\n 'all',\n 'just',\n 'today',\n 'photography',\n 'ipad',\n 'RT',\n 'not',\n 'android',\n 'instagram',\n 'love',\n 'i',\n 'from',\n \"'m\",\n 'fun',\n 'get',\n 'Sony',\n '<',\n '(',\n 'out',\n 'be',\n 'do',\n 'instagood',\n 'are',\n 'music',\n 'got',\n 'beautiful',\n 'news',\n 'funny',\n 'fashion',\n 'case',\n 'Follow',\n 'who',\n 'but',\n 'tech',\n 'This',\n 'time',\n 'work',\n 'galaxy',\n 'photooftheday',\n 'smile',\n 'everyone',\n 'up',\n 'iPad',\n 'app',\n 'ME']"},"metadata":{}}]},{"cell_type":"markdown","source":"# stop words","metadata":{}},{"cell_type":"markdown","source":"> What we can see is that stop words are the most used, but in fact they don't help us determine if a tweet is happy/sad, however, they are consuming memory and they are making the learning process slower, so we really need to get rid of them.","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\n#nltk.download(\"stopwords\")\n\nmw = most_used_words(train_data.tweet.str.cat())\nmost_words = []\nfor w in mw:\n    if len(most_words) == 1000:\n        break\n    if w in stopwords.words(\"english\"):\n        continue\n    else:\n        most_words.append(w)","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"There is 28800 different words\n","output_type":"stream"}]},{"cell_type":"code","source":"# What we did is to filter only non stop words.\n# We will now get a look to the top 1000 words\nsorted(most_words)","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['!',\n '#',\n '$',\n '%',\n '&',\n \"'\",\n \"''\",\n \"'d\",\n \"'ll\",\n \"'m\",\n \"'re\",\n \"'s\",\n \"'ve\",\n '(',\n ')',\n '*',\n '+',\n ',',\n '-',\n '--',\n '.',\n '..',\n '...',\n '/',\n '//bit.ly/rhymeapp',\n '//ebay.to/2yI9MR7',\n '//ift.tt/2aSURcJ',\n '//ift.tt/2boR0kb',\n '//itunes.apple.com/us/app/love360/id809353957',\n '//reallyreal.com/',\n '//steemit.com/photography/',\n '//www.youtube.com/watch',\n '1',\n '10',\n '16',\n '2',\n '20',\n '2011',\n '2012',\n '2014',\n '2015',\n '2016',\n '2017',\n '2018',\n '3',\n '30',\n '4',\n '4G',\n '4s',\n '5',\n '50',\n '5s',\n '6',\n '6s',\n '7',\n '8',\n ':',\n ';',\n '<',\n '=',\n '>',\n '?',\n '@',\n 'A',\n 'ALL',\n 'APPLE',\n 'AT',\n 'Air',\n 'All',\n 'And',\n 'Android',\n 'App',\n 'AppStore',\n 'Apple',\n 'At',\n 'BACK',\n 'Baby',\n 'Be',\n 'Beauty',\n 'Best',\n 'Birthday',\n 'Black',\n 'Book',\n 'But',\n 'Buy',\n 'Ca',\n 'Case',\n 'Cases',\n 'Charm',\n 'Check',\n 'Christmas',\n 'Click',\n 'D',\n 'Dating',\n 'Day',\n 'Decor',\n 'Do',\n 'Download',\n 'Exquisite',\n 'FOLLOW',\n 'FOLLOWBACK',\n 'FREE',\n 'FUCKING',\n 'Facebook',\n 'Family',\n 'Finally',\n 'Follow',\n 'FollowSunday',\n 'Followers',\n 'For',\n 'Free',\n 'Friday',\n 'Fuck',\n 'FuckYou',\n 'GAIN',\n 'Gain',\n 'Galaxy',\n 'Game',\n 'Games',\n 'Get',\n 'God',\n 'Good',\n 'Google',\n 'Got',\n 'Great',\n 'Guys',\n 'HATE',\n 'HTC',\n 'Happy',\n 'Home',\n 'How',\n 'Husband',\n 'I',\n 'ILCE6000',\n 'IOS',\n 'IPHONE',\n 'IPhone',\n 'IS',\n 'IT',\n 'If',\n 'In',\n 'Instagram',\n 'Iphone',\n 'Is',\n 'It',\n 'Its',\n 'Jobs',\n 'Jun',\n 'Just',\n 'Keep',\n 'LOVE',\n 'LTE',\n 'Life',\n 'Like',\n 'Look',\n 'Love',\n 'ME',\n 'MUST',\n 'MY',\n 'Mac',\n 'MacBook',\n 'Make',\n 'May',\n 'Me',\n 'Microsoft',\n 'Mobile',\n 'Monday',\n 'More',\n 'Motorola',\n 'Music',\n 'My',\n 'NEW',\n 'NOT',\n 'New',\n 'News',\n 'No',\n 'Not',\n 'Note',\n 'Now',\n 'OS',\n 'Of',\n 'Oh',\n 'One',\n 'PC',\n 'PS3',\n 'PS4',\n 'Phone',\n 'Photo',\n 'Photobooth',\n 'Please',\n 'Plus',\n 'Pro',\n 'Prophet',\n 'RETWEET',\n 'RT',\n 'Random',\n 'S',\n 'S3',\n 'S4',\n 'S5',\n 'SONY',\n 'Sale',\n 'Samsung',\n 'Saturday',\n 'Selfie',\n 'Share',\n 'Shopping',\n 'Siri',\n 'Smartphone',\n 'Smile',\n 'So',\n 'Sony',\n 'Squishy',\n 'Steemit',\n 'Steve',\n 'Store',\n 'Straps',\n 'Sunday',\n 'Sweet',\n 'T',\n 'THE',\n 'TO',\n 'TV',\n 'Taken',\n 'TeamFollowback',\n 'Thank',\n 'Thanks',\n 'That',\n 'The',\n 'They',\n 'This',\n 'Time',\n 'To',\n 'Toys',\n 'U',\n 'USA',\n 'USB',\n 'Valentine',\n 'Verizon',\n 'WHO',\n 'We',\n 'Well',\n 'What',\n 'White',\n 'Why',\n 'Will',\n 'Windows',\n 'With',\n 'X',\n 'Xperia',\n 'YOU',\n 'Year',\n 'You',\n 'YouTube',\n 'Your',\n '[',\n ']',\n '``',\n 'a6000',\n 'able',\n 'accessories',\n 'account',\n 'actually',\n 'added',\n 'adorable',\n 'ago',\n 'al',\n 'almost',\n 'already',\n 'also',\n 'always',\n 'amazing',\n 'amazon',\n 'android',\n 'annoying',\n 'another',\n 'anyone',\n 'anything',\n 'app',\n 'apple',\n 'applewatch',\n 'apps',\n 'appstore',\n 'arrived',\n 'art',\n 'available',\n 'away',\n 'awesome',\n 'baby',\n 'back',\n 'bad',\n 'battery',\n 'beach',\n 'beautiful',\n 'beauty',\n 'believe',\n 'best',\n 'bestfriend',\n 'bestoftheday',\n 'bestprice',\n 'better',\n 'big',\n 'birthday',\n 'bit',\n 'black',\n 'blackandwhite',\n 'blackberry',\n 'blessed',\n 'blog',\n 'blue',\n 'book',\n 'bots',\n 'bought',\n 'boy',\n 'boyfriend',\n 'brand',\n 'break',\n 'broke',\n 'broken',\n 'brother',\n 'business',\n 'button',\n 'buy',\n 'buying',\n 'ca',\n 'cable',\n 'cake',\n 'call',\n 'came',\n 'camera',\n 'canon',\n 'cant',\n 'capetown',\n 'capetownsup',\n 'car',\n 'card',\n 'care',\n 'case',\n 'cases',\n 'cat',\n 'cause',\n 'cellphone',\n 'change',\n 'charge',\n 'charger',\n 'chargers',\n 'charging',\n 'check',\n 'chocolate',\n 'christmas',\n 'city',\n 'clouds',\n 'code',\n 'coffee',\n 'college',\n 'color',\n 'colors',\n 'come',\n 'coming',\n 'company',\n 'completely',\n 'computer',\n 'computers',\n 'console',\n 'contacts',\n 'cool',\n 'could',\n 'count',\n 'couple',\n 'cover',\n 'cracked',\n 'crap',\n 'crazy',\n 'creative',\n 'customer',\n 'cute',\n 'dad',\n 'daily',\n 'data',\n 'date',\n 'daughter',\n 'day',\n 'days',\n 'dead',\n 'deal',\n 'deals',\n 'decided',\n 'delete',\n 'deleted',\n 'delicious',\n 'design',\n 'device',\n 'devices',\n 'different',\n 'discount',\n 'dj',\n 'dog',\n 'dogs',\n 'done',\n 'dont',\n 'download',\n 'early',\n 'ebay',\n 'else',\n 'email',\n 'emoji',\n 'enjoy',\n 'enough',\n 'entrepreneur',\n 'europe',\n 'even',\n 'ever',\n 'every',\n 'everyone',\n 'everything',\n 'excited',\n 'eyes',\n 'f4f',\n 'face',\n 'facebook',\n 'fact',\n 'fail',\n 'family',\n 'far',\n 'fashion',\n 'fast',\n 'favorite',\n 'features',\n 'feed',\n 'feel',\n 'feeling',\n 'ff',\n 'film',\n 'finally',\n 'find',\n 'first',\n 'fit',\n 'fitness',\n 'fix',\n 'fixed',\n 'florida',\n 'flower',\n 'flowers',\n 'follow',\n 'follow4follow',\n 'followme',\n 'food',\n 'foodporn',\n 'forever',\n 'free',\n 'fresh',\n 'friday',\n 'friend',\n 'friends',\n 'fruit',\n 'fuck',\n 'fucked',\n 'fucking',\n 'fuckyou',\n 'full',\n 'fun',\n 'funny',\n 'future',\n 'gadget',\n 'gadgets',\n 'galaxy',\n 'game',\n 'gamer',\n 'games',\n 'gaming',\n 'garden',\n 'gay',\n 'gear',\n 'geek',\n 'get',\n 'gets',\n 'getting',\n 'gift',\n 'gifts',\n 'girl',\n 'girls',\n 'give',\n 'giving',\n 'glad',\n 'go',\n 'god',\n 'goes',\n 'going',\n 'gold',\n 'gon',\n 'gone',\n 'good',\n 'google',\n 'gorgeous',\n 'got',\n 'gratitude',\n 'great',\n 'green',\n 'guitarplayer',\n 'guy',\n 'guys',\n 'haha',\n 'hair',\n 'half',\n 'hand',\n 'happiness',\n 'happy',\n 'hard',\n 'hashtag',\n 'hate',\n 'hateapple',\n 'headphones',\n 'health',\n 'healthy',\n 'heart',\n 'hello',\n 'help',\n 'holiday',\n 'holidays',\n 'home',\n 'hope',\n 'hot',\n 'hour',\n 'hours',\n 'house',\n 'http',\n 'https',\n 'iMessage',\n 'iOS',\n 'iOS7',\n 'iPad',\n 'iPhone',\n 'iPhone6',\n 'iPhoneX',\n 'iPhones',\n 'iPod',\n 'iTunes',\n 'ig',\n 'igdaily',\n 'igers',\n 'im',\n 'image',\n 'images',\n 'indonesia',\n 'info',\n 'insta',\n 'instacool',\n 'instadaily',\n 'instago',\n 'instagood',\n 'instagood…',\n 'instagram',\n 'instahub',\n 'instalike',\n 'instalove',\n 'instamood',\n 'instapic',\n 'ios',\n 'ios7',\n 'ipad',\n 'ipadmini',\n 'iphone',\n 'iphone4',\n 'iphone4s',\n 'iphone5',\n 'iphone5s',\n 'iphone6',\n 'iphone7',\n 'iphone7plus',\n 'iphone8',\n 'iphonecase',\n 'iphoneography',\n 'iphoneonly',\n 'iphonephotography',\n 'iphonesia',\n 'iphonex',\n 'iphone…',\n 'ipod',\n 'italy',\n 'itunes',\n 'japan',\n 'jj',\n 'job',\n 'joy',\n 'keep',\n 'keeps',\n 'keyboard',\n 'khaoko',\n 'kid',\n 'kids',\n 'kindle',\n 'kiss',\n 'know',\n 'l4l',\n 'landscape',\n 'laptop',\n 'last',\n 'latest',\n 'laugh',\n 'least',\n 'left',\n 'lens',\n 'less',\n 'let',\n 'lg',\n 'life',\n 'lifestyle',\n 'light',\n 'like',\n 'like4like',\n 'likeforlike',\n 'likes',\n 'line',\n 'link',\n 'listen',\n 'literally',\n 'little',\n 'live',\n 'lock',\n 'lol',\n 'london',\n 'long',\n 'longer',\n 'look',\n 'looking',\n 'looks',\n 'lost',\n 'lot',\n 'love',\n 'loving',\n 'ly',\n 'mac',\n 'macbook',\n 'macbookpro',\n 'made',\n 'make',\n 'makes',\n 'makeup',\n 'making',\n 'man',\n 'many',\n 'maps',\n 'market',\n 'may',\n 'men',\n 'message',\n 'messages',\n 'miami',\n 'middle',\n 'might',\n 'mine',\n 'mini',\n 'minute',\n 'minutes',\n 'mirror',\n 'miss',\n 'mobile',\n 'model',\n 'mom',\n 'moment',\n 'money',\n 'month',\n 'months',\n 'mood',\n 'morning',\n 'motorola',\n 'movies',\n 'mt=8',\n 'much',\n 'music',\n 'must',\n \"n't\",\n 'na',\n 'nature',\n 'need',\n 'needs',\n 'never',\n 'new',\n 'newphone',\n 'news',\n 'newtoy',\n 'newyear',\n 'newyork',\n 'next',\n 'nice',\n 'night',\n 'nike',\n 'nofilter',\n 'nokia',\n 'note',\n 'note2',\n 'note3',\n 'nothing',\n 'numbers',\n 'nyc',\n 'offers',\n 'old',\n 'one',\n 'oneplus',\n 'ootd',\n 'open',\n 'orange',\n 'order',\n 'p',\n 'party',\n 'passion',\n 'password',\n 'past',\n 'pay',\n 'peace',\n 'people',\n 'perfect',\n 'pet',\n 'phone',\n 'phonecase',\n 'phonecases',\n 'phones',\n 'photo',\n 'photofeed',\n 'photograph',\n 'photographer',\n 'photography',\n 'photooftheday',\n 'photos',\n 'pic',\n 'picoftheday',\n 'pics',\n 'picture',\n 'pictures',\n 'pie',\n 'piece',\n 'pink',\n 'pissed',\n 'play',\n 'playing',\n 'playstation',\n 'please',\n 'plus',\n 'poem',\n 'pop',\n 'popular',\n 'portrait',\n 'power',\n 'present',\n 'pretty',\n 'pro',\n 'problem',\n 'problems',\n 'product',\n 'products',\n 'proud',\n 'ps3',\n 'ps4',\n 'puppy',\n 'purpose',\n 'put',\n 'quote',\n 'quotes',\n 'rain',\n 'random',\n 'ready',\n 'real',\n 'really',\n 'reason',\n 'red',\n 'redbubble',\n 'relax',\n 'repair',\n 'reset',\n 'restore',\n 'retweet',\n 'rhyme',\n 'rhymes',\n 'right',\n 'room',\n 'rt',\n 'rts',\n 'run',\n 's3',\n 's4',\n 'sad',\n 'said',\n 'sale',\n 'sales',\n 'samsung',\n 'samsung…',\n 'saturday',\n 'say',\n 'saying',\n 'says',\n 'school',\n 'screen',\n 'sea',\n 'see',\n 'selfie',\n 'send',\n 'sent',\n 'seriously',\n 'service',\n 'set',\n 'sexy',\n 'share',\n 'shit',\n 'shitty',\n 'shoot',\n 'shop',\n 'shopping',\n 'shotoniphone',\n 'show',\n 'sick',\n 'simple',\n 'since',\n 'single',\n 'siri',\n 'sister',\n 'sky',\n 'sleep',\n 'small',\n 'smart',\n 'smartphone',\n 'smile',\n 'smiles',\n 'snapspeed…',\n 'software',\n 'someone',\n 'something',\n 'song',\n 'songs',\n 'sony',\n 'sonyalpha',\n 'sonylens',\n 'sonyphoto',\n 'sonyphotography',\n 'sonyphotos',\n 'sony…',\n 'soon',\n 'sorority',\n 'sougofollow',\n 'sound',\n 'spring',\n 'start',\n 'still',\n 'stop',\n 'store',\n 'story',\n 'street',\n 'stuff',\n 'stupid',\n 'style',\n 'suck',\n 'sucks',\n 'summer',\n 'sun',\n 'sunday',\n 'sunset',\n 'sup',\n 'super',\n 'support',\n 'sure',\n 'surf',\n 'swag',\n 'sweet',\n 'switch',\n 'sync',\n 'ta',\n 'tab',\n 'tablet',\n 'take',\n 'taken',\n 'taking',\n 'talk',\n 'tattoo',\n 'tbt',\n 'tech',\n 'technology',\n 'tell',\n 'text',\n 'texts',\n 'thailand',\n 'thank',\n 'thanks',\n 'thankyou',\n 'thing',\n 'things',\n 'think',\n 'though',\n 'thought',\n 'throw',\n 'time',\n 'times',\n 'tired',\n 'tls',\n 'today',\n 'together',\n 'tomorrow',\n 'tonight',\n 'took',\n 'top',\n 'toy',\n 'toys',\n 'travel',\n 'tree',\n 'trip',\n 'truth',\n 'try',\n 'trying',\n 'tuesday',\n 'turn',\n 'tv',\n 'tweegram',\n 'tweet',\n 'twitch',\n 'twitter',\n 'two',\n 'u',\n 'uk',\n 'unitedState',\n 'update',\n 'updated',\n 'updates',\n 'upgrade',\n 'ur',\n 'us',\n 'usa',\n 'use',\n 'used',\n 'user',\n 'users',\n 'using',\n 'utm_campaign=social_autopilot',\n 'utm_medium=tweet',\n 'utm_source=ig_twitter_share',\n 'utm_source=tweet',\n 'valentine',\n 'version',\n 'via',\n 'video',\n 'videos',\n 'vocation',\n 'vsco',\n 'w',\n 'wait',\n 'waiting',\n 'wan',\n 'want',\n 'wants',\n 'watch',\n 'water',\n 'way',\n 'wedding',\n 'week',\n 'weekend',\n 'weeks',\n 'well',\n 'went',\n 'white',\n 'whole',\n 'wife',\n 'wifi',\n 'win',\n 'windows',\n 'wish',\n 'without',\n 'wo',\n 'woman',\n 'wont',\n 'word',\n 'words',\n 'work',\n 'working',\n 'works',\n 'world',\n 'worst',\n 'would',\n 'wow',\n 'wrong',\n 'xbox',\n 'xperia',\n 'ya',\n 'yay',\n 'yeah',\n 'year',\n 'years',\n 'yes',\n 'yesterday',\n 'yet',\n 'youtube',\n 'yum',\n 'yummy',\n 'zeeland',\n '|',\n 'Андроид',\n '–',\n '—',\n '‘',\n '’',\n '“',\n '”',\n '•',\n '…']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Stemming","metadata":{}},{"cell_type":"markdown","source":"> You should have noticed something, right? There are words that have the same meaning, but written in a different manner, sometimes in the plural and sometimes with a suffix (ing, es ...), this will make our model think that they are different words and also make our vocabulary bigger (waste of memory and time for the learning process). The solution is to reduce those words with the same root, this is called stemming.","metadata":{}},{"cell_type":"code","source":"# I'm defining this function to use it in the \n# Data Preparation Phase\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\n\n#nltk.download('wordnet')\ndef stem_tokenize(text):\n    stemmer = SnowballStemmer(\"english\")\n    stemmer = WordNetLemmatizer()\n    return [stemmer.lemmatize(token) for token in word_tokenize(text)]\n\ndef lemmatize_tokenize(text):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(token) for token in word_tokenize(text)]","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":">  will stop here, but you can visualize tweets more and more to gain insights and take decisions about how to transform your data.","metadata":{}},{"cell_type":"markdown","source":"# Prepare the data","metadata":{}},{"cell_type":"markdown","source":"> In this phase, we will transform our tweets into a more usable data by our ML models.","metadata":{}},{"cell_type":"markdown","source":"# Bag of Words","metadata":{}},{"cell_type":"markdown","source":"We are going to use the Bag of Words algorithm, which basically takes a text as input, extract words from it (this is our vocabulary) to use them in the vectorization process. When a tweet comes in, it will vectorize it by counting the number of occurrences of each word in our vocabulary.\n\nFor example, we have this two tweets: \"I learned a lot today\" and \"hahaha I got you\".\n\n> #  tweet / words       I     learned     a     lot    today    hahaha      got    you\n \n1. > #  first            1      1          1      1      1        0          0       0\n   \n* > #  second            1      0          0      0      0        1          1       1","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Building the pipeline","metadata":{}},{"cell_type":"markdown","source":"> It's always a good practice to make a pipeline of transformation for your data, it will make the process of data transformation really easy and reusable. We will implement a pipeline for transforming our tweets to something that our ML models can digest (vectors)","metadata":{}},{"cell_type":"code","source":"from sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# We need to do some preprocessing of the tweets.\n# We will delete useless strings (like @, # ...)\n# because we think that they will not help\n# in determining if the person is Happy/Sad\n\nclass TextPreProc(BaseEstimator,TransformerMixin):\n    def __init__(self, use_mention=False):\n        self.use_mention = use_mention\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        # We can choose between keeping the mentions\n        # or deleting them\n        if self.use_mention:\n            X = X.str.replace(r\"@[a-zA-Z0-9_]* \", \" @tags \")\n        else:\n            X = X.str.replace(r\"@[a-zA-Z0-9_]* \", \"\")\n            \n        # Keeping only the word after the #\n        X = X.str.replace(\"#\", \"\")\n        X = X.str.replace(r\"[-\\.\\n]\", \"\")\n        # Removing HTML garbage\n        X = X.str.replace(r\"&\\w+;\", \"\")\n        # Removing links\n        X = X.str.replace(r\"https?://\\S*\", \"\")\n        # replace repeated letters with only two occurences\n        # heeeelllloooo => heelloo\n        X = X.str.replace(r\"(.)\\1+\", r\"\\1\\1\")\n        # mark emoticons as happy or sad\n        X = X.str.replace(HAPPY_EMO, \" happyemoticons \")\n        X = X.str.replace(SAD_EMO, \" sademoticons \")\n        X = X.str.lower()\n        return X","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# This is the pipeline that will transform our tweets to something eatable.\n# You can see that we are using our previously defined stemmer, it will\n# take care of the stemming process.\n# For stop words, we let the inverse document frequency do the job\nfrom sklearn.model_selection import train_test_split\n\nsentiments = train_data['label']\ntweets = train_data['tweet']\n\n# I get those parameters from the 'Fine tune the model' part\nvectorizer = TfidfVectorizer(tokenizer=lemmatize_tokenize, ngram_range=(1,2))\npipeline = Pipeline([\n    ('text_pre_processing', TextPreProc(use_mention=True)),\n    ('vectorizer', vectorizer),\n])\n\n# Let's split our data into learning set and testing set\n# This process is done to test the efficency of our model at the end.\n# You shouldn't look at the test data only after choosing the final model\nlearn_data, test_data, sentiments_learning, sentiments_test = train_test_split(tweets, sentiments, test_size=0.3)\n\n# This will tranform our learning data from simple text to vector\n# by going through the preprocessing tranformer.\nlearning_data = pipeline.fit_transform(learn_data)","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Select a model","metadata":{}},{"cell_type":"markdown","source":"> When we have our data ready to be processed by ML models, the question we should ask is which model to use?\n> \n> The answer varies depending on the problem and data, for example, it's known that Naive Bias has proven good efficacy against Text Based Problems.\n> \n> A good way to choose a model is to try different candidate, evaluate them using cross validation, then chose the best one which will be later tested against our test data.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\n\nlr = LogisticRegression()\nbnb = BernoulliNB()\nmnb = MultinomialNB()\n\nmodels = {\n    'logitic regression': lr,\n    'bernoulliNB': bnb,\n    'multinomialNB': mnb,\n}\n\nfor model in models.keys():\n    scores = cross_val_score(models[model], learning_data, sentiments_learning, scoring=\"f1\", cv=10)\n    print(\"===\", model, \"===\")\n    print(\"scores = \", scores)\n    print(\"mean = \", scores.mean())\n    print(\"variance = \", scores.var())\n    models[model].fit(learning_data, sentiments_learning)\n    print(\"score on the learning data (accuracy) = \", accuracy_score(models[model].predict(learning_data), sentiments_learning))\n    print(\"\")","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"=== logitic regression ===\nscores =  [0.6557377  0.67213115 0.6090535  0.66945607 0.63865546 0.69166667\n 0.61666667 0.73895582 0.70119522 0.59504132]\nmean =  0.6588559577595945\nvariance =  0.0018324049614875221\nscore on the learning data (accuracy) =  0.9256854256854257\n\n=== bernoulliNB ===\nscores =  [0.4744186  0.51818182 0.5470852  0.51351351 0.62222222 0.60633484\n 0.51101322 0.62337662 0.52017937 0.55111111]\nmean =  0.5487436524535472\nvariance =  0.002423318604056238\nscore on the learning data (accuracy) =  0.9332611832611832\n\n=== multinomialNB ===\nscores =  [0.50485437 0.47       0.51674641 0.48241206 0.48730964 0.49756098\n 0.48039216 0.54368932 0.46766169 0.53773585]\nmean =  0.4988362478846593\nvariance =  0.0006429778313069493\nscore on the learning data (accuracy) =  0.9444444444444444\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> None of those models is likely to be overfitting, I will choose the multinomialNB.","metadata":{}},{"cell_type":"markdown","source":"# Fine tune the model","metadata":{}},{"cell_type":"markdown","source":"> I'm going to use the GridSearchCV to choose the best parameters to use.\n> \n> What the GridSearchCV does is trying different set of parameters, and for each one, it runs a cross validation and estimate the score. At the end we can see what are the best parameter and use them to build a better classifier.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ngrid_search_pipeline = Pipeline([\n    ('text_pre_processing', TextPreProc()),\n    ('vectorizer', TfidfVectorizer()),\n    ('model', MultinomialNB()),\n])\n\nparams = [\n    {\n        'text_pre_processing__use_mention': [True, False],\n        'vectorizer__max_features': [1000, 2000, 5000, 10000, 20000, None],\n        'vectorizer__ngram_range': [(1,1), (1,2)],\n    },\n]\ngrid_search = GridSearchCV(grid_search_pipeline, params, cv=5, scoring='f1')\ngrid_search.fit(learn_data, sentiments_learning)\nprint(grid_search.best_params_)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'text_pre_processing__use_mention': True, 'vectorizer__max_features': 5000, 'vectorizer__ngram_range': (1, 2)}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> Testing our model against data other than the data used for training our model will show how well the model is generalising on new data.","metadata":{}},{"cell_type":"markdown","source":"# Note","metadata":{}},{"cell_type":"markdown","source":"We shouldn't test to choose the model, this will only let us confirm that the choosen model is doing well.","metadata":{}},{"cell_type":"code","source":"mnb.fit(learning_data, sentiments_learning)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"MultinomialNB()"},"metadata":{}}]},{"cell_type":"code","source":"testing_data = pipeline.transform(test_data)\nmnb.score(testing_data, sentiments_test)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.8409090909090909"},"metadata":{}}]},{"cell_type":"code","source":"sub_data = pd.read_csv(\"../input/twitter-dataset/test_twitter.csv\", encoding='ISO-8859-1')","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"sub_data","metadata":{"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"        id  \\\n0     7921   \n1     7922   \n2     7923   \n3     7924   \n4     7925   \n...    ...   \n1948  9869   \n1949  9870   \n1950  9871   \n1951  9872   \n1952  9873   \n\n                                                                                                    tweet  \n0                           I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks  \n1     currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://insta...  \n2     I'd like to puts some CD-ROMS on my iPad, is that possible?' â Yes, but wouldn't that block th...  \n3     My ipod is officially dead. I lost all my pictures and videos from the 1D and 5sos concert,and f...  \n4                                  Been fighting iTunes all night! I only want the music I $&@*# paid for  \n...                                                                                                   ...  \n1948  #SamsungGalaxyNote7 Explodes, Burns 6-Year-Old. Thanks for rushing your products to market #Sams...  \n1949  Now Available - Hoodie. Check it out here - http://zetasupplies.co.uk/products/hoodie-2?utm_camp...  \n1950  There goes a crack right across the screen. If you could actually provide a more durable screen,...  \n1951                           @codeofinterest as i said #Adobe big time we may well as include #apple to  \n1952  Finally I got it .. thanx my father .. #Samsung #galaxy #s3 #gift #father #phone #new http://ins...  \n\n[1953 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7921</td>\n      <td>I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7922</td>\n      <td>currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://insta...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7923</td>\n      <td>I'd like to puts some CD-ROMS on my iPad, is that possible?' â Yes, but wouldn't that block th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7924</td>\n      <td>My ipod is officially dead. I lost all my pictures and videos from the 1D and 5sos concert,and f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7925</td>\n      <td>Been fighting iTunes all night! I only want the music I $&amp;@*# paid for</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>9869</td>\n      <td>#SamsungGalaxyNote7 Explodes, Burns 6-Year-Old. Thanks for rushing your products to market #Sams...</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>9870</td>\n      <td>Now Available - Hoodie. Check it out here - http://zetasupplies.co.uk/products/hoodie-2?utm_camp...</td>\n    </tr>\n    <tr>\n      <th>1950</th>\n      <td>9871</td>\n      <td>There goes a crack right across the screen. If you could actually provide a more durable screen,...</td>\n    </tr>\n    <tr>\n      <th>1951</th>\n      <td>9872</td>\n      <td>@codeofinterest as i said #Adobe big time we may well as include #apple to</td>\n    </tr>\n    <tr>\n      <th>1952</th>\n      <td>9873</td>\n      <td>Finally I got it .. thanx my father .. #Samsung #galaxy #s3 #gift #father #phone #new http://ins...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1953 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Predecting on the test.csv\n\nsub_learning = pipeline.transform(sub_data.tweet)\nsub = pd.DataFrame(sub_data.id, columns=(\"id\", \"label\"))\nsub[\"label\"] = mnb.predict(sub_learning)\nprint(sub)","metadata":{"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"        id  label\n0     7921      1\n1     7922      0\n2     7923      0\n3     7924      0\n4     7925      0\n...    ...    ...\n1948  9869      0\n1949  9870      0\n1950  9871      0\n1951  9872      0\n1952  9873      0\n\n[1953 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test your tweet","metadata":{}},{"cell_type":"markdown","source":"> The most exciting part ! Don't be too hard with my classifier...","metadata":{}},{"cell_type":"code","source":"# Just run it\nmodel = MultinomialNB()\nmodel.fit(learning_data, sentiments_learning)\ntweet = pd.Series([input(),])\ntweet = pipeline.transform(tweet)\nproba = model.predict_proba(tweet)[0]\nprint(\"The probability that this tweet is sad is:\", proba[0])\nprint(\"The probability that this tweet is happy is:\", proba[1])","metadata":{"trusted":true},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdin","text":" Happy\n"},{"name":"stdout","text":"The probability that this tweet is sad is: 0.9719787681735573\nThe probability that this tweet is happy is: 0.028021231826441933\n","output_type":"stream"}]},{"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"sample_submission_text_analysis.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(sub)\n\n# create a link to download the dataframe\ncreate_download_link(df)\n\n# ↓ ↓ ↓  Yay, download link! ↓ ↓ ↓ ","metadata":{"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a download=\"sample_submission_text_analysis.csv\" href=\"data:text/csv;base64,id,label
7921,1
7922,0
7923,0
7924,0
7925,0
7926,0
7927,0
7928,0
7929,0
7930,0
7931,0
7932,0
7933,0
7934,0
7935,0
7936,0
7937,0
7938,1
7939,1
7940,0
7941,0
7942,0
7943,0
7944,0
7945,0
7946,0
7947,0
7948,0
7949,1
7950,0
7951,0
7952,0
7953,0
7954,0
7955,0
7956,0
7957,1
7958,0
7959,0
7960,0
7961,0
7962,0
7963,0
7964,1
7965,0
7966,0
7967,0
7968,0
7969,0
7970,0
7971,0
7972,0
7973,0
7974,0
7975,0
7976,0
7977,0
7978,0
7979,0
7980,0
7981,0
7982,0
7983,0
7984,0
7985,0
7986,0
7987,0
7988,0
7989,0
7990,0
7991,0
7992,0
7993,0
7994,0
7995,1
7996,0
7997,0
7998,0
7999,0
8000,1
8001,0
8002,0
8003,0
8004,0
8005,0
8006,1
8007,0
8008,0
8009,0
8010,0
8011,0
8012,0
8013,0
8014,0
8015,0
8016,1
8017,1
8018,0
8019,0
8020,1
8021,0
8022,0
8023,0
8024,1
8025,0
8026,0
8027,1
8028,0
8029,0
8030,0
8031,0
8032,0
8033,0
8034,0
8035,0
8036,0
8037,0
8038,0
8039,0
8040,1
8041,0
8042,0
8043,0
8044,0
8045,0
8046,0
8047,0
8048,1
8049,1
8050,1
8051,1
8052,0
8053,0
8054,0
8055,0
8056,0
8057,0
8058,0
8059,0
8060,0
8061,0
8062,0
8063,0
8064,0
8065,0
8066,1
8067,0
8068,0
8069,0
8070,0
8071,0
8072,0
8073,1
8074,0
8075,0
8076,0
8077,0
8078,0
8079,0
8080,0
8081,0
8082,1
8083,0
8084,0
8085,0
8086,0
8087,0
8088,0
8089,0
8090,1
8091,0
8092,0
8093,0
8094,0
8095,0
8096,0
8097,0
8098,0
8099,0
8100,0
8101,0
8102,0
8103,1
8104,0
8105,0
8106,0
8107,0
8108,0
8109,0
8110,0
8111,0
8112,0
8113,0
8114,0
8115,0
8116,0
8117,0
8118,0
8119,0
8120,0
8121,0
8122,0
8123,0
8124,0
8125,0
8126,0
8127,0
8128,0
8129,0
8130,0
8131,0
8132,1
8133,0
8134,0
8135,0
8136,0
8137,0
8138,0
8139,0
8140,0
8141,0
8142,0
8143,0
8144,0
8145,0
8146,0
8147,0
8148,0
8149,0
8150,0
8151,0
8152,0
8153,0
8154,0
8155,0
8156,0
8157,0
8158,0
8159,0
8160,1
8161,0
8162,0
8163,0
8164,0
8165,0
8166,0
8167,0
8168,1
8169,0
8170,0
8171,0
8172,0
8173,0
8174,0
8175,1
8176,0
8177,0
8178,0
8179,0
8180,0
8181,0
8182,0
8183,0
8184,0
8185,1
8186,0
8187,0
8188,0
8189,0
8190,0
8191,0
8192,0
8193,0
8194,0
8195,0
8196,0
8197,0
8198,1
8199,0
8200,0
8201,1
8202,0
8203,0
8204,0
8205,0
8206,0
8207,0
8208,0
8209,0
8210,0
8211,0
8212,0
8213,1
8214,0
8215,0
8216,0
8217,0
8218,0
8219,0
8220,0
8221,0
8222,0
8223,0
8224,1
8225,0
8226,1
8227,1
8228,0
8229,0
8230,0
8231,0
8232,1
8233,1
8234,0
8235,0
8236,0
8237,0
8238,0
8239,0
8240,0
8241,0
8242,0
8243,0
8244,0
8245,1
8246,1
8247,0
8248,0
8249,0
8250,0
8251,0
8252,1
8253,0
8254,0
8255,0
8256,0
8257,0
8258,0
8259,1
8260,0
8261,0
8262,0
8263,0
8264,0
8265,0
8266,1
8267,0
8268,0
8269,0
8270,1
8271,0
8272,0
8273,1
8274,0
8275,0
8276,0
8277,0
8278,0
8279,0
8280,0
8281,1
8282,0
8283,0
8284,0
8285,1
8286,1
8287,0
8288,1
8289,0
8290,0
8291,0
8292,0
8293,0
8294,0
8295,1
8296,0
8297,1
8298,0
8299,0
8300,0
8301,0
8302,0
8303,0
8304,0
8305,1
8306,1
8307,0
8308,0
8309,0
8310,0
8311,1
8312,0
8313,0
8314,0
8315,0
8316,0
8317,0
8318,0
8319,0
8320,1
8321,0
8322,0
8323,0
8324,1
8325,0
8326,0
8327,0
8328,0
8329,0
8330,0
8331,0
8332,0
8333,0
8334,0
8335,0
8336,0
8337,0
8338,0
8339,0
8340,0
8341,0
8342,0
8343,0
8344,0
8345,0
8346,0
8347,0
8348,0
8349,0
8350,0
8351,1
8352,0
8353,0
8354,0
8355,1
8356,1
8357,0
8358,0
8359,0
8360,0
8361,0
8362,0
8363,0
8364,0
8365,0
8366,0
8367,0
8368,0
8369,0
8370,1
8371,0
8372,0
8373,0
8374,0
8375,0
8376,0
8377,0
8378,0
8379,0
8380,0
8381,0
8382,0
8383,0
8384,0
8385,0
8386,0
8387,1
8388,0
8389,0
8390,0
8391,0
8392,0
8393,0
8394,0
8395,0
8396,0
8397,0
8398,0
8399,0
8400,0
8401,0
8402,0
8403,0
8404,0
8405,0
8406,0
8407,1
8408,0
8409,1
8410,0
8411,0
8412,0
8413,0
8414,0
8415,0
8416,0
8417,0
8418,0
8419,0
8420,0
8421,0
8422,0
8423,0
8424,1
8425,0
8426,0
8427,1
8428,0
8429,0
8430,0
8431,0
8432,0
8433,0
8434,0
8435,0
8436,0
8437,0
8438,0
8439,0
8440,0
8441,0
8442,0
8443,0
8444,1
8445,0
8446,0
8447,0
8448,0
8449,0
8450,0
8451,0
8452,0
8453,0
8454,0
8455,1
8456,0
8457,0
8458,0
8459,0
8460,0
8461,0
8462,0
8463,0
8464,0
8465,0
8466,0
8467,0
8468,0
8469,0
8470,0
8471,0
8472,1
8473,1
8474,0
8475,1
8476,0
8477,0
8478,1
8479,0
8480,0
8481,0
8482,0
8483,0
8484,0
8485,0
8486,0
8487,0
8488,0
8489,0
8490,1
8491,1
8492,0
8493,1
8494,0
8495,1
8496,0
8497,1
8498,0
8499,0
8500,0
8501,0
8502,1
8503,0
8504,0
8505,0
8506,0
8507,0
8508,0
8509,0
8510,0
8511,0
8512,0
8513,0
8514,0
8515,1
8516,0
8517,0
8518,0
8519,0
8520,0
8521,0
8522,0
8523,0
8524,0
8525,0
8526,1
8527,0
8528,0
8529,0
8530,0
8531,0
8532,0
8533,0
8534,0
8535,0
8536,0
8537,0
8538,0
8539,0
8540,0
8541,0
8542,0
8543,0
8544,0
8545,0
8546,0
8547,0
8548,0
8549,1
8550,0
8551,0
8552,0
8553,0
8554,1
8555,0
8556,1
8557,1
8558,0
8559,0
8560,0
8561,0
8562,0
8563,0
8564,0
8565,0
8566,0
8567,0
8568,0
8569,0
8570,0
8571,0
8572,0
8573,0
8574,0
8575,0
8576,0
8577,0
8578,1
8579,0
8580,0
8581,0
8582,0
8583,0
8584,0
8585,0
8586,0
8587,0
8588,0
8589,0
8590,0
8591,0
8592,0
8593,0
8594,0
8595,0
8596,0
8597,0
8598,0
8599,0
8600,0
8601,0
8602,0
8603,0
8604,1
8605,0
8606,0
8607,0
8608,0
8609,0
8610,0
8611,0
8612,1
8613,0
8614,1
8615,0
8616,0
8617,0
8618,1
8619,0
8620,0
8621,0
8622,0
8623,0
8624,0
8625,0
8626,1
8627,1
8628,0
8629,0
8630,0
8631,0
8632,0
8633,1
8634,1
8635,0
8636,0
8637,0
8638,0
8639,0
8640,1
8641,0
8642,0
8643,0
8644,0
8645,0
8646,0
8647,0
8648,0
8649,0
8650,0
8651,0
8652,0
8653,0
8654,0
8655,0
8656,0
8657,0
8658,0
8659,0
8660,0
8661,0
8662,0
8663,0
8664,0
8665,1
8666,0
8667,1
8668,0
8669,0
8670,0
8671,0
8672,1
8673,0
8674,0
8675,0
8676,0
8677,0
8678,0
8679,0
8680,0
8681,0
8682,0
8683,0
8684,0
8685,0
8686,0
8687,0
8688,0
8689,1
8690,0
8691,1
8692,0
8693,0
8694,0
8695,0
8696,0
8697,0
8698,0
8699,0
8700,0
8701,0
8702,0
8703,1
8704,1
8705,0
8706,0
8707,0
8708,0
8709,0
8710,0
8711,0
8712,0
8713,0
8714,0
8715,0
8716,0
8717,0
8718,0
8719,0
8720,0
8721,1
8722,0
8723,0
8724,0
8725,0
8726,0
8727,0
8728,0
8729,0
8730,1
8731,0
8732,0
8733,1
8734,0
8735,0
8736,0
8737,0
8738,1
8739,0
8740,0
8741,0
8742,0
8743,0
8744,0
8745,0
8746,0
8747,1
8748,0
8749,0
8750,1
8751,0
8752,0
8753,0
8754,0
8755,0
8756,0
8757,0
8758,0
8759,0
8760,0
8761,0
8762,0
8763,0
8764,1
8765,0
8766,0
8767,0
8768,1
8769,0
8770,0
8771,0
8772,0
8773,0
8774,1
8775,0
8776,0
8777,1
8778,0
8779,0
8780,0
8781,0
8782,0
8783,0
8784,0
8785,0
8786,0
8787,0
8788,0
8789,1
8790,0
8791,0
8792,0
8793,0
8794,0
8795,0
8796,0
8797,0
8798,0
8799,0
8800,0
8801,0
8802,0
8803,0
8804,0
8805,0
8806,0
8807,0
8808,0
8809,0
8810,1
8811,0
8812,0
8813,1
8814,0
8815,0
8816,1
8817,0
8818,0
8819,1
8820,0
8821,0
8822,0
8823,0
8824,0
8825,0
8826,1
8827,0
8828,0
8829,0
8830,1
8831,0
8832,0
8833,0
8834,0
8835,0
8836,0
8837,1
8838,0
8839,0
8840,0
8841,0
8842,0
8843,0
8844,0
8845,0
8846,0
8847,0
8848,0
8849,0
8850,0
8851,0
8852,0
8853,0
8854,0
8855,0
8856,0
8857,0
8858,0
8859,0
8860,0
8861,0
8862,0
8863,0
8864,0
8865,0
8866,0
8867,0
8868,0
8869,1
8870,0
8871,0
8872,0
8873,1
8874,0
8875,0
8876,0
8877,0
8878,0
8879,0
8880,0
8881,0
8882,0
8883,0
8884,0
8885,1
8886,0
8887,0
8888,0
8889,0
8890,0
8891,0
8892,0
8893,0
8894,0
8895,0
8896,0
8897,0
8898,1
8899,0
8900,0
8901,0
8902,0
8903,1
8904,0
8905,0
8906,0
8907,0
8908,0
8909,0
8910,0
8911,0
8912,0
8913,0
8914,0
8915,0
8916,1
8917,0
8918,0
8919,0
8920,0
8921,0
8922,0
8923,0
8924,0
8925,0
8926,1
8927,0
8928,0
8929,0
8930,0
8931,0
8932,0
8933,0
8934,0
8935,0
8936,0
8937,0
8938,0
8939,0
8940,0
8941,0
8942,0
8943,0
8944,0
8945,0
8946,0
8947,1
8948,0
8949,0
8950,0
8951,0
8952,0
8953,0
8954,0
8955,0
8956,0
8957,0
8958,1
8959,1
8960,0
8961,0
8962,0
8963,0
8964,0
8965,0
8966,0
8967,0
8968,0
8969,1
8970,0
8971,0
8972,0
8973,0
8974,0
8975,0
8976,0
8977,0
8978,0
8979,1
8980,0
8981,0
8982,0
8983,0
8984,0
8985,0
8986,0
8987,0
8988,0
8989,0
8990,0
8991,0
8992,0
8993,0
8994,0
8995,0
8996,0
8997,0
8998,0
8999,0
9000,0
9001,0
9002,0
9003,0
9004,0
9005,0
9006,1
9007,0
9008,0
9009,0
9010,0
9011,0
9012,0
9013,0
9014,0
9015,0
9016,0
9017,0
9018,0
9019,0
9020,0
9021,0
9022,0
9023,0
9024,0
9025,0
9026,0
9027,0
9028,0
9029,0
9030,0
9031,0
9032,0
9033,0
9034,1
9035,0
9036,0
9037,0
9038,0
9039,0
9040,0
9041,0
9042,0
9043,0
9044,0
9045,0
9046,0
9047,0
9048,0
9049,0
9050,0
9051,0
9052,0
9053,0
9054,0
9055,0
9056,1
9057,0
9058,0
9059,0
9060,1
9061,0
9062,0
9063,1
9064,0
9065,0
9066,0
9067,0
9068,0
9069,0
9070,0
9071,0
9072,1
9073,0
9074,0
9075,1
9076,0
9077,0
9078,0
9079,1
9080,0
9081,0
9082,0
9083,0
9084,1
9085,0
9086,0
9087,0
9088,0
9089,0
9090,0
9091,0
9092,0
9093,0
9094,0
9095,0
9096,0
9097,0
9098,0
9099,0
9100,1
9101,0
9102,0
9103,0
9104,0
9105,0
9106,1
9107,0
9108,0
9109,0
9110,0
9111,0
9112,1
9113,0
9114,0
9115,0
9116,0
9117,0
9118,0
9119,0
9120,0
9121,1
9122,0
9123,0
9124,0
9125,0
9126,0
9127,0
9128,0
9129,0
9130,0
9131,0
9132,0
9133,0
9134,0
9135,0
9136,0
9137,0
9138,0
9139,1
9140,0
9141,0
9142,0
9143,0
9144,0
9145,0
9146,0
9147,0
9148,0
9149,0
9150,0
9151,0
9152,0
9153,0
9154,0
9155,1
9156,0
9157,0
9158,1
9159,0
9160,0
9161,0
9162,0
9163,0
9164,0
9165,0
9166,1
9167,0
9168,0
9169,0
9170,0
9171,0
9172,1
9173,1
9174,0
9175,1
9176,0
9177,0
9178,0
9179,1
9180,0
9181,0
9182,0
9183,0
9184,0
9185,0
9186,0
9187,0
9188,0
9189,0
9190,0
9191,0
9192,0
9193,1
9194,0
9195,0
9196,0
9197,1
9198,0
9199,0
9200,0
9201,0
9202,0
9203,0
9204,0
9205,0
9206,0
9207,1
9208,0
9209,0
9210,0
9211,0
9212,0
9213,0
9214,1
9215,0
9216,0
9217,0
9218,0
9219,0
9220,0
9221,0
9222,0
9223,0
9224,0
9225,0
9226,0
9227,0
9228,0
9229,0
9230,0
9231,0
9232,0
9233,0
9234,1
9235,0
9236,0
9237,0
9238,0
9239,0
9240,0
9241,0
9242,0
9243,1
9244,0
9245,0
9246,0
9247,0
9248,0
9249,0
9250,1
9251,1
9252,0
9253,0
9254,0
9255,0
9256,0
9257,0
9258,0
9259,0
9260,0
9261,0
9262,0
9263,0
9264,0
9265,0
9266,0
9267,0
9268,0
9269,1
9270,0
9271,0
9272,0
9273,0
9274,0
9275,1
9276,0
9277,0
9278,0
9279,0
9280,0
9281,1
9282,0
9283,0
9284,0
9285,0
9286,0
9287,0
9288,0
9289,1
9290,0
9291,0
9292,0
9293,0
9294,0
9295,0
9296,0
9297,0
9298,1
9299,0
9300,0
9301,0
9302,0
9303,0
9304,0
9305,0
9306,0
9307,0
9308,0
9309,0
9310,0
9311,1
9312,0
9313,0
9314,0
9315,0
9316,0
9317,0
9318,0
9319,0
9320,0
9321,0
9322,0
9323,0
9324,0
9325,0
9326,0
9327,0
9328,0
9329,0
9330,0
9331,0
9332,1
9333,0
9334,0
9335,0
9336,0
9337,0
9338,0
9339,0
9340,0
9341,0
9342,0
9343,0
9344,0
9345,0
9346,0
9347,0
9348,0
9349,1
9350,0
9351,0
9352,0
9353,0
9354,0
9355,0
9356,0
9357,0
9358,0
9359,0
9360,0
9361,0
9362,0
9363,0
9364,0
9365,0
9366,0
9367,0
9368,0
9369,0
9370,0
9371,0
9372,1
9373,0
9374,0
9375,0
9376,0
9377,1
9378,0
9379,0
9380,0
9381,0
9382,1
9383,0
9384,0
9385,0
9386,0
9387,0
9388,0
9389,0
9390,0
9391,0
9392,0
9393,0
9394,0
9395,1
9396,0
9397,0
9398,1
9399,0
9400,0
9401,0
9402,0
9403,0
9404,0
9405,0
9406,0
9407,0
9408,0
9409,0
9410,0
9411,0
9412,0
9413,0
9414,0
9415,0
9416,0
9417,0
9418,0
9419,0
9420,0
9421,0
9422,0
9423,1
9424,0
9425,0
9426,0
9427,0
9428,0
9429,0
9430,0
9431,0
9432,1
9433,1
9434,0
9435,0
9436,0
9437,0
9438,0
9439,1
9440,0
9441,1
9442,0
9443,0
9444,0
9445,0
9446,0
9447,0
9448,0
9449,0
9450,0
9451,1
9452,0
9453,0
9454,0
9455,0
9456,0
9457,0
9458,0
9459,0
9460,0
9461,0
9462,0
9463,0
9464,0
9465,0
9466,0
9467,0
9468,0
9469,0
9470,0
9471,1
9472,0
9473,1
9474,0
9475,0
9476,0
9477,1
9478,0
9479,0
9480,0
9481,1
9482,0
9483,0
9484,0
9485,0
9486,0
9487,1
9488,0
9489,0
9490,0
9491,0
9492,0
9493,0
9494,0
9495,0
9496,0
9497,0
9498,0
9499,0
9500,0
9501,0
9502,1
9503,0
9504,0
9505,0
9506,0
9507,0
9508,0
9509,0
9510,0
9511,0
9512,0
9513,0
9514,0
9515,0
9516,0
9517,0
9518,0
9519,1
9520,0
9521,0
9522,0
9523,0
9524,0
9525,0
9526,1
9527,0
9528,0
9529,0
9530,0
9531,0
9532,0
9533,0
9534,0
9535,0
9536,0
9537,0
9538,0
9539,0
9540,0
9541,0
9542,0
9543,0
9544,0
9545,0
9546,0
9547,0
9548,0
9549,0
9550,0
9551,0
9552,0
9553,0
9554,1
9555,0
9556,0
9557,0
9558,0
9559,0
9560,0
9561,0
9562,0
9563,0
9564,0
9565,0
9566,0
9567,0
9568,0
9569,0
9570,0
9571,0
9572,0
9573,0
9574,0
9575,0
9576,0
9577,0
9578,0
9579,0
9580,0
9581,0
9582,0
9583,0
9584,0
9585,0
9586,0
9587,0
9588,0
9589,0
9590,0
9591,0
9592,0
9593,0
9594,0
9595,0
9596,0
9597,0
9598,0
9599,0
9600,0
9601,0
9602,0
9603,1
9604,0
9605,0
9606,0
9607,0
9608,0
9609,0
9610,0
9611,0
9612,0
9613,0
9614,0
9615,0
9616,0
9617,0
9618,0
9619,0
9620,0
9621,0
9622,0
9623,0
9624,0
9625,0
9626,0
9627,0
9628,0
9629,1
9630,0
9631,0
9632,0
9633,0
9634,0
9635,0
9636,0
9637,0
9638,0
9639,1
9640,1
9641,0
9642,0
9643,0
9644,0
9645,0
9646,1
9647,0
9648,0
9649,0
9650,0
9651,0
9652,1
9653,0
9654,0
9655,1
9656,1
9657,0
9658,0
9659,0
9660,0
9661,1
9662,0
9663,0
9664,0
9665,0
9666,0
9667,1
9668,0
9669,0
9670,0
9671,0
9672,0
9673,1
9674,0
9675,0
9676,0
9677,1
9678,0
9679,0
9680,0
9681,0
9682,0
9683,0
9684,0
9685,1
9686,0
9687,0
9688,0
9689,0
9690,1
9691,0
9692,0
9693,0
9694,0
9695,0
9696,1
9697,0
9698,0
9699,0
9700,0
9701,0
9702,1
9703,0
9704,0
9705,0
9706,0
9707,0
9708,0
9709,0
9710,1
9711,0
9712,0
9713,1
9714,0
9715,1
9716,0
9717,1
9718,0
9719,0
9720,0
9721,0
9722,0
9723,0
9724,0
9725,0
9726,0
9727,0
9728,0
9729,0
9730,0
9731,0
9732,0
9733,0
9734,0
9735,0
9736,0
9737,0
9738,0
9739,0
9740,0
9741,1
9742,1
9743,0
9744,0
9745,0
9746,0
9747,0
9748,0
9749,0
9750,0
9751,0
9752,0
9753,0
9754,0
9755,0
9756,0
9757,0
9758,1
9759,0
9760,0
9761,0
9762,0
9763,0
9764,0
9765,0
9766,1
9767,1
9768,0
9769,0
9770,0
9771,1
9772,0
9773,0
9774,0
9775,0
9776,0
9777,0
9778,1
9779,0
9780,0
9781,0
9782,0
9783,0
9784,0
9785,0
9786,0
9787,0
9788,1
9789,0
9790,0
9791,0
9792,0
9793,0
9794,0
9795,0
9796,0
9797,0
9798,0
9799,0
9800,0
9801,0
9802,0
9803,1
9804,0
9805,0
9806,0
9807,0
9808,0
9809,1
9810,0
9811,0
9812,0
9813,1
9814,1
9815,1
9816,0
9817,0
9818,0
9819,0
9820,0
9821,0
9822,0
9823,0
9824,0
9825,1
9826,1
9827,0
9828,0
9829,0
9830,1
9831,0
9832,0
9833,0
9834,0
9835,0
9836,0
9837,0
9838,0
9839,0
9840,1
9841,1
9842,0
9843,0
9844,0
9845,0
9846,1
9847,0
9848,0
9849,0
9850,0
9851,1
9852,1
9853,0
9854,0
9855,0
9856,0
9857,0
9858,0
9859,0
9860,0
9861,0
9862,0
9863,0
9864,0
9865,0
9866,0
9867,0
9868,0
9869,0
9870,0
9871,0
9872,0
9873,0
\" target=\"_blank\">Download CSV file</a>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}